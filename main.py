# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license

import argparse
from typing import List, Tuple, Union

import sys
sys.path.insert(0, '/home/eden/opencv/opencv-4.10.0/build_cuda/lib/python3')  # æ ¹æ“šä½ çš„å¯¦éš›è·¯å¾‘èª¿æ•´
# sys.path.insert(0, '/home/user/opencv/opencv/build_cuda/lib/python3')  # æ ¹æ“šä½ çš„å¯¦éš›è·¯å¾‘èª¿æ•´

import cv2
print("cv2 loaded from:", cv2.__file__)
print("OpenCV version:", cv2.__version__)
# print("Build Info:")
# print(cv2.getBuildInformation())
print("CUDA-enabled device count:", cv2.cuda.getCudaEnabledDeviceCount())

import time
import numpy as np
import torch
import torch.nn.functional as F
from collections import defaultdict

import ultralytics.utils.ops as ops
from ultralytics import YOLO
from ultralytics.engine.results import Results
from ultralytics.utils import ASSETS, YAML
from ultralytics.utils.checks import check_yaml
 
from utils.transform import RP
from utils.visualize import draw_box_and_mask
from utils.video_utils import load_video, resize_frame_gpu, get_video_properties

import platform
import os

def is_jetson():
    return (
        platform.machine() == 'aarch64' and
        (os.path.exists('/etc/nv_tegra_release') or os.path.exists('/etc/nvidia-container-runtime'))
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--export", type=str, default=False, help="Export .pt to .engine")
    parser.add_argument("--model", type=str, required=True, default="yolo11m-seg.pt", help="Path to ONNX model")
    parser.add_argument("--source", type=str, default=str(ASSETS / "bus.jpg"), help="Path to input image")
    parser.add_argument("--conf", type=float, default=0.3, help="Confidence threshold")
    parser.add_argument("--iou", type=float, default=0.7, help="NMS IoU threshold")
    parser.add_argument("--resize_ratio", type=float, default=1.0, help="Video resize ratio")
    parser.add_argument("--rtsp", type=str)
    args = parser.parse_args()

    if args.export:
        if not args.model.endswith(".pt"):  
            raise NotImplementedError
        pt_model = YOLO(args.model)        
        pt_model.export(format="engine", int8=True, dynamic=True, half=False)
        model = YOLO(args.model.replace(".pt",".engine"))  
    else:
        if args.model.endswith(".pt") and args.export is not True:       
            from yolo.yolo_seg_onnx import YOLOv8Seg_onnx 
            from utils.segmentor import process_frame
            model = YOLO(args.model)
        elif args.model.endswith(".pt") and args.export:
            from yolo.yolo_seg_trt import YOLOv8Seg_TRT    
            from utils.segmentor_trt import process_frame        
            model = YOLO(args.model)          
        elif args.model.endswith(".engine"):
            if is_jetson():
                print("Jetson device ")
                from yolo.yolo_seg_trt_jetson import YOLOv8Seg_TRT
            else:
                from yolo.yolo_seg_trt import YOLOv8Seg_TRT
            from utils.segmentor_trt import process_frame
            model = YOLO(args.model)
            
            # from yolo.yolo_seg_trt import YOLOv8Seg_TRT    
            # from utils.segmentor_trt import process_frame        
            # model = YOLO(args.model)          
        elif args.model.endswith(".onnx"):
            from yolo.yolo_seg_onnx import YOLOv8Seg_onnx
            from utils.segmentor import process_frame
            model = YOLOv8Seg_onnx(args.model, args.conf, args.iou)
        else: 
            raise NotImplementedError

    if(args.rtsp):
        video = load_video(args.rtsp)
    else:
        # è®€å–å½±ç‰‡
        video = load_video('./test/suitcase3.mp4')
        # video = load_video('./test/output_preprocess_1.mp4')
        # video = load_video('./test/772104971.057013.mp4')
        
    # å–å¾—å½±ç‰‡åƒæ•¸
    width, height, fps = get_video_properties(video)

    # è¼¸å‡ºå½±ç‰‡è¨­å®šï¼ˆè«‹æ ¹æ“šresizeèª¿æ•´å°ºå¯¸ï¼Œè¦ç‰¹åˆ¥æ³¨æ„å°ºå¯¸æ˜¯ (width, height)ï¼‰
    output_resize_width = int(width * args.resize_ratio)
    output_resize_height = int(height * args.resize_ratio)
    resize_size = (output_resize_width, output_resize_height)  # resizeçš„å°ºå¯¸(å¯¬,é«˜)  

    allowed_classes={28}

    colors = {
        # 0: (255, 0, 0),     # person
        28: (0, 255, 0),  # suitcase
    }
    
    # è®€å–ç¬¬ä¸€å¹€è¨­å®šROIç¯„åœ
    ret, first_frame = video.read()
    if not ret:
        print("ç„¡æ³•è®€å–å½±ç‰‡")
        exit()

    # Upload to GPU and resize      
    frame_resized = resize_frame_gpu(first_frame, resize_size)
    
    # ä½¿ç”¨è€…é¸é»žä¸¦å–å¾—çŸ¯æ­£åœ–èˆ‡åŽŸå§‹å››é»ž
    # M = RP.photo_PR_roi(frame_resized)
    ## å»ºç«‹å·²å°è£ç‰©ä»¶
    M, max_width, max_height = RP().photo_PR_roi(frame_resized)

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter("test/output.mp4", fourcc, fps, (int(max_width), int(max_height)))
    
    # Store the track history
    track_history = defaultdict(lambda: [])
    track_time_history = defaultdict(list)
    track_box_history = defaultdict(list)

    while True:
        ret, frame = video.read()            
        if not ret:
            video.set(cv2.CAP_PROP_POS_FRAMES, 0)
            track_history = defaultdict(lambda: [])
            track_time_history = defaultdict(list)
            track_box_history = defaultdict(list)
            continue
            # break
        
        start_time = time.time()

        try:
            # Resize frame on GPU
            frame_resized = resize_frame_gpu(frame, resize_size)
            
            output = process_frame(model, frame_resized, M, max_width, max_height, colors, track_history, track_time_history, track_box_history, allowed_classes)

            end_time = time.time()
            FPS = 1/(end_time - start_time)
            # print(f"Frame latency: {latency_ms:.2f} ms")
            print(f"FPS: {FPS:.2f}", end='\r')
            if output is not None and output.size > 0:
                out.write(output)
                cv2.imshow("Segmented Image", output)
            else:
                print("Skipped empty frame (write/show).")
            # cv2.imshow("Original Image", frame_resized)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        except Exception as e:
            print(f"Error during frame processing: {e}")
            break            

    video.release()
    out.release()  # é‡‹æ”¾ VideoWriter

    cv2.destroyAllWindows() 