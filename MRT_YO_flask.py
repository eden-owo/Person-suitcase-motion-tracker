#
#å¯ä½¿ç”¨ä¹‹éŽæ¸¡ç‰ˆ
#åµæ¸¬åˆåœ¨ç•«éª¨æž¶ä¸­
#æœªæ¨¡çµ„åŒ–
#æœªåŠ å…¥è¡ŒæŽ
#ç„¡é™æ’­æ”¾+ç”¢æ–‡å­—æª”
#åŠ å…¥.cpu.numpy
#torch cudaå·²åŠ 
#

from flask import Flask, Response, stream_with_context
from ultralytics import YOLO
import threading
import cv2
import time
import math
import numpy as np
import time as time10
import os
yolo_model = YOLO('yolo11m-pose.pt')

all_connect = [
    (5,7), (7,9),(6,8), (8,10),
    (5,11), (6,12), (5,6),(11,12),
    (11,13), (13,15), (12,14), (14,16)
]

hand_connect = [(5,7), (7,9),(6,8), (8,10)]
body_connect = [(5,11), (6,12), (5,6),(11,12)]
leg_connect = [(11,13), (13,15), (12,14), (14,16)]

app = Flask(__name__)

@app.route('/')
def index():
    return "âœ… Flask æ­£å¸¸é‹ä½œ"

@app.route('/pose')
def pose():
    return Response(stream_with_context(generate_stream()),
                    mimetype='multipart/x-mixed-replace; boundary=frame')
    # return Response("é€™è£¡æ˜¯å½±ç‰‡ä¸²æµå…§å®¹", mimetype='text/plain')
    
def start_flask():
    print("ðŸš€ Flask é–‹å§‹é‹è¡Œåœ¨ http://0.0.0.0:5000/")
    # app.run(host='0.0.0.0', port=5000, ssl_context=('192.168.1.22.pem', '192.168.1.22-key.pem'))
    app.run(host='0.0.0.0', port=5000)
    
def generate_stream():     
    while True:
        try:
            if output_frame is None:
                time.sleep(0.01)
                continue

            ret, jpeg = cv2.imencode('.jpg', output_frame)
            if not ret:
                continue
            frame_bytes = jpeg.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        except Exception as e:
            print(f"[Stream Error] {e}")
            time.sleep(0.1)

    
#å½±ç‰‡è¨­å®š
video_path_1 = r'E:\otoTim\MRTpose\testvideo\67sA18.mp4'
video_path_2 = r'E:\otoTim\MRTpose\testvideo\short1p.mp4'
video_path_3 = r'E:\otoTim\MRTpose\testvideo\A02_0604.avi'
video_path_4 = r'E:\otoTim\MRTpose\testvideo\A21_0604.avi'
video_path_5 = r'E:\otoTim\MRTpose\testvideo\A02_0604_2.mp4'
video_path_6 = r'E:\otoTim\MRTpose\testvideo\FB_0605.mp4'
video_path_7 = r'E:\otoTim\MRTpose\testvideo\FB_0606.mp4'
video_path_8 = r'E:\otoTim\MRTpose\testvideo\A08_0606_1.mp4'
video_path_9 = r'E:\otoTim\MRTpose\testvideo\A08_0606_2.mp4'
video_path_10 = r'E:\otoTim\MRTpose\testvideo\A12_0606_1.mp4'
video_path_11 = r'E:\otoTim\MRTpose\testvideo\A12_0606_2.mp4'
video_path_12 = r'E:\otoTim\MRTpose\testvideo\A12_0606_3.mp4'
video_path_13 = r'E:\otoTim\MRTpose\testvideo\TPE_0606_1.mp4'
video_path_14 = r'E:\otoTim\MRTpose\testvideo\TPE_0606_2.mp4'
video_path_15 = r'E:\otoTim\MRTpose\testvideo\FB_0609.mp4'

# RTSP = r'rtsp://admin:Pass1234@192.168.1.102:554/stream0'
RTSP_FILE = os.getenv("RTSP_FILE", "/workspace/Person-suitcase-motion-tracker/rtsp.txt")  # å¯ç”¨ç’°å¢ƒè®Šæ•¸è¦†è“‹è·¯å¾‘
with open(RTSP_FILE, "r", encoding="utf-8") as f:
    RTSP = f.read().strip()

# RTSP = r'rtsp://admin:Pass1234@192.168.1.200:554/stream0'
alarm_output = r'/workspace/pose/alarm/fall_detect.txt'

cap = cv2.VideoCapture(RTSP)
prev_time = 0

#è¨­å®šä½¿ç”¨è®Šæ•¸
alarm = 0
alarm_keep_frame = 30
alarm_txt_sec = 60
tag_time = 0
delta_time = 0
size_check = 0
new_size_check = 0
detect_degree = 50

flask_thread = threading.Thread(target=start_flask)
flask_thread.daemon = True    
flask_thread.start()

global output_frame

while cap.isOpened():
    
    ret, frame = cap.read()
    if not ret:
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        continue
    
    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    if size_check == 0 :
        print ("screen width = ", original_width)
        print ("screen height = ", original_height)
        size_check = 1
    results = yolo_model(frame, verbose=False)

    # è­¦å ±è™•ç†
    # è­¦å ±æ¨£æ…‹æœƒåˆ·æ–°è­¦å ±åƒæ•¸ï¼Œå¦å‰‡è®€å¹€æ™‚æ…¢æ…¢æ¸›å°‘
    if alarm > 0:
        alarm = alarm - 1
    
    for i in range(len(results[0].boxes)):
        #èª¿å–resultä¸­boundingboxå’Œkeypoint
        box = results[0].boxes.xyxy[i].cpu().numpy()
        # box = results[0].boxes.xyxy[i]
        x1, y1, x2, y2 = map(int, box)
        
        keypoints = results[0].keypoints.xy[i].cpu().numpy()
        confidences = results[0].keypoints.conf[i].cpu().numpy()  # æ¯å€‹é—œç¯€çš„ä¿¡å¿ƒæŒ‡æ•¸
        #è³¦äºˆèº«é«”ç¯€é»žåº§æ¨™èˆ‡æ˜¯å¦æœ‰æ•ˆçš„é—œè¯æ€§
        #åˆ¤æ–·ç¯€é»žçš„æœ‰æ•ˆæ€§
        #å› é è¨­ç‚º(0,0)ï¼Œæ‰€ä»¥åªè¦æ˜¯(0,0)å°±è¨­ç‚ºç„¡æ•ˆ
        #j>4ç”¨ä¾†å¿½ç•¥é ­éƒ¨ç¯€é»ž
        points = {}
        for j, (keypoint, conf) in enumerate(zip(keypoints, confidences)):

            if j > 4:
                x, y = int(keypoint[0]), int(keypoint[1])
                if conf < 0.6:  # é–€æª»å€¼ï¼Œå¯èª¿æ•´ï¼ˆ0.3ï½ž0.5å¸¸è¦‹ï¼‰
                    negate_point = 1
                else:
                    negate_point = 0

                if (x, y) == (0, 0):
                    negate_point = 1
                else:
                    negate_point = 0
                
                points[j] = (x, y, negate_point)
                #cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)
        
        #ä¸‹é¢ä½¿ç”¨åˆ°çš„åƒæ•¸è¨­å®š
        left_line = 0
        right_line = 0
        left_degree = 0
        right_degree = 0
        body_degree = 0
        alarm_sloping = 0
        alarm_knee_location = 0
        draw_lines = [] #è¦ç•«çš„ç·šæ¢è³‡è¨Š
        #ä¾åºå–å‡ºæ¨™è¨˜å°ï¼Œè‹¥å…©è€…çš†ç‚ºæœ‰æ•ˆé»žå†ç•«ç·š
        #ä¾åºå¾žall_connectå–å‡ºåº§æ¨™å°(a,b)
        #å†å¾žpoint{}ä¸­å–å‡ºpoint[a]å’Œpoint[b]
        #æŽ¥è‘—å­˜çµ¦skp,ekp
        for connect_idx, (start_kp, end_kp) in enumerate(all_connect):
            if start_kp in points and end_kp in points:
                x_skp, y_skp, negate_skp = points[start_kp]
                x_ekp, y_ekp, negate_ekp = points[end_kp]                
                
                if (negate_skp == 0) and (negate_ekp == 0): 
                # if (x1 <= x_skp <= x2) and (x1 <= x_ekp <= x2) and (y1 <= y_skp <= y2) and (y1 <= y_ekp <= y2):
                #é€™è¡Œå¯ä»¥è®“é€£ç·šåªå­˜åœ¨æ–¼æ¡†å…§
                #æ¡†å¤–çš„ç¯€é»žæ˜¯æ¨¡åž‹é æ¸¬çš„
                    
                    if (0 <= connect_idx <=3):
                        hand_color = (255, 0, 179)
                        hand_line_width =  3
                        draw_lines.append(((x_skp, y_skp), (x_ekp, y_ekp), hand_color, hand_line_width))
                    
                    elif (4 <= connect_idx <=7):  
                        body_color = (0, 0, 255)
                        body_line_width = 3
                        draw_lines.append(((x_skp, y_skp), (x_ekp, y_ekp), body_color, body_line_width))
                        
                        #èº«é«”å·¦å³ç·šè™•ç†
                        if (connect_idx == 4):
                            if (negate_skp == 0) and (negate_ekp == 0):
                                o_point = (0,0)
                                p_point = ((x_skp-x_ekp),(y_ekp-y_skp))
                                left_line = 1
                                left_degree = (math.degrees(math.atan2(*p_point)))
                        
                        if (connect_idx == 5):
                            if (negate_skp == 0) and (negate_ekp == 0):
                                o_point = (0,0)
                                p_point = ((x_skp-x_ekp),(y_ekp-y_skp))
                                right_line = 1
                                right_degree = (math.degrees(math.atan2(*p_point)))
                    
                    elif (8 <= connect_idx <=11):
                        leg_color = (0, 77, 255)
                        leg_line_width = 3
                        draw_lines.append(((x_skp, y_skp), (x_ekp, y_ekp), leg_color, leg_line_width))
                        
                        if (connect_idx == 8) or (connect_idx == 10):
                            if (y_skp >= y_ekp):
                                alarm = alarm_keep_frame
                                alarm_knee_location = 1

        #è¨ˆç®—è§’åº¦
        if (left_line == 0) or (right_line == 0) :
            body_degree = abs(left_degree + right_degree)
        else :
            body_degree = ((abs(left_degree + right_degree))/2)

        if (body_degree >= detect_degree):
            alarm = alarm_keep_frame
            alarm_sloping = 1
            #print("Alarm_sloping :",f"{body_degree:.2f}")

        #ç•«æ¡†ã€æ¨™è§’åº¦                       
        if alarm_knee_location == 1:
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
            for pt1, pt2, color, thickness in draw_lines:
                cv2.line(frame, pt1, pt2, color, thickness)
            cv2.putText(frame, f'degree: {body_degree:.2f}', (x1, y1),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                
        # if (alarm_sloping == 1):
            # cv2.putText(frame, f'degree: {body_degree:.2f}', (x1, y1),
            # cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        # else:
        #     cv2.putText(frame, f'degree: {body_degree:.2f}', (x1, y1),
        #     cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)

        # if (alarm_knee_location == 1):
        #     cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
            #print("Alarm_knee_location")
        # else:
        #     cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)

    #frameè¼¸å‡ºã€èª¿æ•´ç•«é¢å¤§å°ã€è¨ˆç®—FPSã€ç™¼è­¦å ±
    h, w = frame.shape[:2]

    #if (original_width > 1920) or (original_height > 1080):
    if (original_width > 960) or (original_height > 540):
        resize_width = (w // 2)
        resize_height = (h // 2)
        resized_frame = cv2.resize(frame, (resize_width, resize_height))
        if (new_size_check == 0):
            print ("new width = ", resize_width)
            print ("new height = ", resize_height)
            new_size_check = 1
        
    else:
        resized_frame = cv2.resize(frame, (w, h))
    
    curr_time = time.time()
    #fps = 1 / (curr_time - prev_time) if prev_time else 0
    if prev_time:
        delta_time = (curr_time-prev_time)
        fps = (1 / delta_time)
    else:
        fps = 0
    prev_time = curr_time
    #print(f"FPSï¼š{fps}")

    # cv2.putText(resized_frame, f'FPS: {fps:.2f}', (20, 40),
    # cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    if alarm > 0:
        if (tag_time <= 0):
            tag_time = alarm_txt_sec
            with open(alarm_output, "w", encoding="utf-8") as alarm_txt:
                alarm_txt.write('ALARM')
                print("output txt")
        else:
            tag_time = (tag_time - delta_time)
            #print("tag time = ", tag_time)

        # cv2.putText(resized_frame, f'ALARM', (20, 80),
        # cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 4)

    else:
        tag_time = (tag_time - delta_time)
        #print("tag time = ", tag_time)
    
    #cv2.imshow('PoseLandmarker (Tasks API)', resized_frame)
    output_frame = resized_frame
    if cv2.waitKey(1) & 0xFF == 27:
        print("End video")
        break

    #frame_idx += 1

cap.release()
cv2.destroyAllWindows()

